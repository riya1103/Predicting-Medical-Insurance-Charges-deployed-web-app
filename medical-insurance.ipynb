{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\nimport time\nimport seaborn as sns\n# You can write up to 5GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.pipeline import make_pipeline","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Data Loading","execution_count":null},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"df = pd.read_csv(\"/kaggle/input/insurance/insurance.csv\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.columns","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y = df[\"charges\"]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X = df[['age', 'sex', 'bmi', 'children', 'smoker', 'region']]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X['region'].unique().tolist()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X = pd.get_dummies(X,drop_first=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import seaborn as sbn","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"corr = df.corr()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sbn.heatmap(corr,annot=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def Normalize(data):\n    return (data - np.min(data)) / (np.max(data) - np.min(data))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y=Normalize(y)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X[[\"age\",\"bmi\",\"children\"]] = Normalize(X[[\"age\",\"bmi\",\"children\"]])\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Train and test data splitting","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 0)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import matplotlib.pyplot as plt","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Linear Regression","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.linear_model import LinearRegression\nregressor = LinearRegression()\nregressor.fit(X_train, y_train)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_pred = regressor.predict(X_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn import  linear_model, metrics \nreg = linear_model.LinearRegression() \nreg.fit(X_train,y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#FINDING THE COEFFECIENTS \ncoef = reg.coef_","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"coef","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"1.86280803e-01* 0.021739","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X.iloc[0]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y.iloc[0]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X.iloc[0]*coef","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"val = sum(X.iloc[0]*coef)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"val","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#POSSIBLE INTERCEPT VALUE\nb0 = y.iloc[0]-val\nb0","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#REAL INTERCEPT VALUE\nreg.intercept_","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Accuracy and error calculation","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# Applying k-Fold Cross Validation\nfrom sklearn.model_selection import cross_val_score\naccuracies = cross_val_score(estimator = regressor, X = X_train, y = y_train, cv = 10)\naccuracies.std()\naccuracies.mean()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import cross_val_score\naccuracies = cross_val_score(estimator = reg, X = X_train, y = y_train, cv = 10)\naccuracies.std()\naccuracies.mean()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import explained_variance_score","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"explained_variance_score(y_test, y_pred)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import max_error","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"max_error(y_test, y_pred)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from yellowbrick.regressor import ResidualsPlot\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"visualizer = ResidualsPlot(regressor)\nvisualizer.fit(X_train, y_train)  # Fit the training data to the visualizer\nvisualizer.score(X_test, y_test)  # Evaluate the model on the test data\nvisualizer.show()  \n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import mean_absolute_error","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"mean_absolute_error(y_test, y_pred)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import mean_squared_error","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"mean_squared_error(y_test, y_pred)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import median_absolute_error","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"median_absolute_error(y_test, y_pred)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import r2_score","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"r = r2_score(y_test, y_pred)\nr","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"0.2*1338","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# def adjustedrsq(r,n,k):\n#     return 1-[(1-r**2)(n-1)/(n-k-1)]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# n = 268\n# k = 8\n# adj_r_sq = adjustedrsq(r,n,k)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import mean_poisson_deviance","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# mean_poisson_deviance(y_test, y_pred)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import mean_gamma_deviance","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# mean_gamma_deviance(y_test, y_pred)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#USING OLS TO CALCULATE MORE INSIGHTS","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Using OLS model to have a better summary report ","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"import statsmodels.api as sm\nfrom matplotlib import pyplot as plt\nX1_train = sm.add_constant(X_train)\nX1_test = sm.add_constant(X_test)\nmod_fit = sm.OLS(y_train,X1_train).fit()\nres = mod_fit.resid # residuals\nfig = sm.qqplot(res,line='45')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#OBSERVE THE CONST VALUE IS THE SAME AS THE INTERCEPT VALUE IN THE SKLEARN MODEL and the coeffs too.\nmod_fit.params","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"mod_fit.summary()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.corr()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X.corr()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Feature selection after analysing t-test values and probability values of each feature","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"X_ols = X_train[[\"age\",\"bmi\",\"children\",\"smoker_yes\"]]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_ols_test = X_test[[\"age\",\"bmi\",\"children\",\"smoker_yes\"]]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_ols.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"len(y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_ols_train = X_ols[:1070]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"len(X_ols_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_ols_train.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_train.values.reshape(-1,1)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_train","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import statsmodels.api as sm\nX_ols_trains = sm.add_constant(X_ols_train)\nmod_fit2 = sm.OLS(y_train,X_ols_trains).fit()\nres2 = mod_fit2.resid # residuals\nfig = sm.qqplot(res2,line='45')\nplt.show()\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"mod_fit2.params","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"mod_fit2.summary()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"mod_fit2.predict(X_ols_trains)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_ols_test = sm.add_constant(X_ols_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_pred_ols = mod_fit2.predict(X_ols_test)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Calculating accuracy and error again after feature selection ","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"mean_squared_error(y_test, y_pred_ols)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"max_error(y_test, y_pred_ols)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"explained_variance_score(y_test, y_pred_ols)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"explained_variance_score(y_test, y_pred)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# from sklearn.model_selection import validation_curve","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# train_scores, valid_scores = validation_curve(regressor, X, y,\"gamma\",\n#                                                np.logspace(-7, 3, 3),\n#                                                cv=5)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Learning Curve","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import learning_curve\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_sizes, train_scores, validation_scores = learning_curve(\n     regressor, X, y, train_sizes=[1,10, 100, 200,500], cv=5,shuffle=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print('Training scores:\\n\\n', train_scores)\nprint('\\n', '-' * 70) # separator to make the output easy to read\nprint('\\nValidation scores:\\n\\n', validation_scores)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_scores_mean = -train_scores.mean(axis = 1)\nvalidation_scores_mean = -validation_scores.mean(axis = 1)\nprint('Mean training scores\\n\\n', pd.Series(train_scores_mean, index = train_sizes))\nprint('\\n', '-' * 20) # separator\nprint('\\nMean validation scores\\n\\n',pd.Series(validation_scores_mean, index = train_sizes))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import matplotlib.pyplot as plt\n\nplt.style.use('seaborn')\nplt.plot(train_sizes, train_scores_mean, label = 'Training error')\nplt.plot(train_sizes, validation_scores_mean, label = 'Validation error')\nplt.ylabel('MSE', fontsize = 14)\nplt.xlabel('Training set size', fontsize = 14)\nplt.title('Learning curves for a linear regression model', fontsize = 18)\nplt.legend()\n\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Support Vector Regression (SVR) ","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.svm import SVR","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Comparing different kernel performances","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"svr = SVR(kernel=\"rbf\")\nsvr.fit(X_train,y_train)\ny_svr = svr.predict(X_test)\nfrom sklearn.model_selection import cross_val_score\naccuracies = cross_val_score(estimator = svr, X = X_train, y = y_train, cv = 10)\naccuracies.std()\naccuracies.mean()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"r2_score(y_test,y_svr)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"svr.get_params()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"svr.score(X_test,y_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"svr2 = SVR(kernel=\"linear\")\nsvr2.fit(X_train,y_train)\ny_svr2 = svr2.predict(X_test)\nfrom sklearn.model_selection import cross_val_score\naccuracies = cross_val_score(estimator = svr2, X = X_train, y = y_train, cv = 10)\naccuracies.std()\naccuracies.mean()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"svr2.score(X_test,y_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"svr2 = SVR(kernel=\"poly\")\nsvr2.fit(X_train,y_train)\ny_svr2 = svr2.predict(X_test)\nfrom sklearn.model_selection import cross_val_score\naccuracies = cross_val_score(estimator = svr2, X = X_train, y = y_train, cv = 10)\naccuracies.std()\naccuracies.mean()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"svr2.score(X_test,y_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"svr2 = SVR(kernel=\"sigmoid\")\nsvr2.fit(X_train,y_train)\ny_svr2 = svr2.predict(X_test)\nfrom sklearn.model_selection import cross_val_score\naccuracies = cross_val_score(estimator = svr2, X = X_train, y = y_train, cv = 10)\naccuracies.std()\naccuracies.mean()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"svr2.score(X_test,y_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import GridSearchCV\n\n# Set the parameters by cross-validation\ntuned_parameters = [{'kernel': ['rbf'], 'gamma': [1e-3, 1e-4],\n                     'C': [1, 10, 100, 1000]},\n                    {'kernel': ['linear'], 'C': [1, 10, 100, 1000]}]\n\nclf = GridSearchCV(SVR(), tuned_parameters)\nclf.fit(X_train, y_train)\nprint(clf.best_params_)\nmeans = clf.cv_results_['mean_test_score']\nstds = clf.cv_results_['std_test_score']\n    \n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"svr2 = SVR(kernel=\"rbf\",C=1000,gamma=0.001)\nsvr2.fit(X_train,y_train)\ny_svr2 = svr2.predict(X_test)\nfrom sklearn.model_selection import cross_val_score\naccuracies = cross_val_score(estimator = svr2, X = X_train, y = y_train, cv = 10)\naccuracies.std()\naccuracies.mean()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"means","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Decision Tree Regressor","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.tree import DecisionTreeRegressor  \n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"treg = DecisionTreeRegressor()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"treg.fit(X_train,y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_predt = treg.predict(X_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"treg.get_params()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import cross_val_score\naccuracies = cross_val_score(estimator = treg, X = X_train, y = y_train, cv = 10)\naccuracies.std()\naccuracies.mean()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"treg.fit(X_ols_train,y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_ols_train.shape\nX_ols_test.shape\nX_ols_test","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_ols_test = X_ols_test[[\"age\",\"bmi\",\"children\",\"smoker_yes\"]]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_predt2 = treg.predict(X_ols_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import cross_val_score\naccuracies = cross_val_score(estimator = treg, X = X_ols_train, y = y_train, cv = 10)\naccuracies.std()\naccuracies.mean()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"treg.score(X_ols_test, y_test)\ntreg.score(X_ols_train, y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"treg.decision_path(X_ols_train,check_input=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"treg.feature_importances_","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Lets see if this feature importances let us know the difference b/w X_train and X_ols_train as the ols model did\ntreg_check = DecisionTreeRegressor()\ntreg_check.fit(X_train,y_train)\ntreg_check.feature_importances_","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Yes it showed\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"treg.get_depth()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"treg.get_n_leaves()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Cost complexity Pruning path","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"treg.cost_complexity_pruning_path(X_ols_train, y_train, sample_weight=None)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Return the index of the leaf that each sample is predicted as.\ntreg.apply(X_ols_train)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Using AdaBoost for optimizing performance ","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.ensemble import AdaBoostRegressor\n\nada_reg = AdaBoostRegressor(DecisionTreeRegressor(max_depth=25),\n                          n_estimators=300)\n\n\nada_reg.fit(X_ols_train, y_train)\n\n# Predict\ny_2 = ada_reg.predict(X_ols_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import cross_val_score\naccuracies = cross_val_score(estimator = ada_reg, X = X_ols_train, y = y_train, cv = 10)\naccuracies.std()\naccuracies.mean()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# from sklearn.tree import export_graphviz  \n# import graphviz\n\n# reg_check2 = DecisionTreeRegressor()\n# # export the decision tree to a tree.dot file \n# # for visualizing the plot easily anywhere \n# X_chck = X_ols_train['smoker_yes']\n# X_chck = X_chck.values.reshape(-1,1)\n# reg_check2.fit(X_chck,y_train)\n\n# export_graphviz(reg_check2, out_file ='tree.dot',feature_names =['bmi'])  \n\n# dot_data = tree.export_graphviz(reg_check2, out_file=None, \n#                                 feature_names=[\"smoker_yes\"],\n#                                 filled=True)\n# # Draw graph\n# graph = graphviz.Source(dot_data, format=\"png\") \n# graph","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Visualising tree in different ways","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn import tree\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"text_representation = tree.export_text(treg)\nprint(text_representation)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_ols_train.columns","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fig = plt.figure(figsize=(25,20))\n_ = tree.plot_tree(treg, feature_names=['age', 'bmi', 'children', 'smoker_yes'], filled=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pip install dtreeviz\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# from dtreeviz.trees import dtreeviz # remember to load the package\n\n# viz = dtreeviz(treg, X_ols_train, y_train,\n#                 target_name=\"charges\",\n#                 feature_names=['age', 'bmi', 'children', 'smoker_yes'])\n# viz","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"param_grid = {\"criterion\": [\"mse\", \"mae\"],\n              \"min_samples_split\": [10, 20, 40,60],\n              \"max_depth\": [2, 6, 8,0,15,20,21,23,25],\n              \"min_samples_leaf\": [20, 40, 100,200],\n              \"max_leaf_nodes\": [5, 20,50, 100,150,200],\n              }\n\n## Comment in order to publish in kaggle.\n\ngrid_cv = GridSearchCV(treg, param_grid, cv=10)\n\ngrid_cv.fit(X_ols_train,y_train)\ngrid_df =  pd.DataFrame(data=grid_cv.cv_results_)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"grid_cv.cv_results_","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"grid_cv.best_params_","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"treg_imp = DecisionTreeRegressor(criterion= 'mse',\n max_depth= 8,\n max_leaf_nodes= 20,\n min_samples_leaf= 20,\n min_samples_split= 10)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"treg_imp.fit(X_ols_train,y_train)\ny_pred_imp = treg_imp.predict(X_ols_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import cross_val_score\naccuracies = cross_val_score(estimator = treg_imp, X = X_ols_train, y = y_train, cv = 10)\naccuracies.std()\naccuracies.mean()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"grid_df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fig,ax = plt.subplots()\nsns.pointplot(data=grid_df[['mean_test_score',\n                           'param_max_leaf_nodes',\n                           'param_max_depth']],\n             y='mean_test_score',x='param_max_depth',\n             hue='param_max_leaf_nodes',ax=ax)\nax.set(title=\"Effect of Depth and Leaf Nodes on Model Performance\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Evaluating training model\npredicted = y_pred_imp\nresiduals = y_test.values.flatten()-predicted\n\nfig, ax = plt.subplots()\nax.scatter(y_test.values.flatten(), residuals)\nax.axhline(lw=2,color='black')\nax.set_xlabel('Observed')\nax.set_ylabel('Residual')\nplt.show()\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Evaluating training model\npredicted = y_pred_imp\nresiduals = y_test.values.flatten()-predicted\n\nfig, ax = plt.subplots()\nax.scatter(y_test.values.flatten(), predicted)\nax.axhline(lw=2,color='black')\nax.set_xlabel('Observed')\nax.set_ylabel('predicted ')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"treg_imp.score(X_ols_test, y_test)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"treg_imp.score(X_ols_train, y_train)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Learning Curve","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"from yellowbrick.model_selection import LearningCurve\nvisualizer = LearningCurve(treg, scoring='r2')\nvisualizer.fit(X, y)        # Fit the data to the visualizer\nvisualizer.show()  ","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# **RANDOM FOREST**","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.ensemble import RandomForestRegressor\nreg_rf = RandomForestRegressor(random_state=0)\nreg_rf.fit(X_train, y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"reg_rf.feature_importances_","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_pred_rf = reg_rf.predict(X_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import cross_val_score\naccuracies = cross_val_score(estimator = reg_rf, X = X_train, y = y_train, cv = 10)\naccuracies.std()\naccuracies.mean()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_ols_train.shape\nX_ols_test.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.ensemble import RandomForestRegressor\nreg_rf = RandomForestRegressor(n_estimators=100,criterion=\"mse\",max_depth = None,\n                               max_features='log2', bootstrap=True, n_jobs=-1,verbose = 0,oob_score=True)\nreg_rf.fit(X_ols_train, y_train)\ny_pred_rf = reg_rf.predict(X_ols_test)\n\nfrom sklearn.model_selection import cross_val_score\naccuracies = cross_val_score(estimator = reg_rf, X = X_ols_train, y = y_train, cv = 5)\naccuracies.std()\naccuracies.mean()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Remember oob score is on unseen data!","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"reg_rf.oob_score_","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"reg_rf.oob_prediction_","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"reg_rf.score(X_ols_train,y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"reg_rf.feature_importances_","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"reg_rf.score(X_ols_test,y_test)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Using yellowbrick.model_selection for building Learning Curve as it is very easy this way.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"from yellowbrick.model_selection import LearningCurve\nvisualizer = LearningCurve(reg_rf, scoring='r2')\nvisualizer.fit(X, y)        # Fit the data to the visualizer\nvisualizer.show()  ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from yellowbrick.model_selection import LearningCurve\nvisualizer = LearningCurve(reg_rf, scoring='r2')\nvisualizer.fit(X_ols_train, y_train)        # Fit the data to the visualizer\nvisualizer.show()  ","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Calculating oob score (Out of bag) for every max_features option","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.ensemble import RandomForestRegressor\nc1 = RandomForestRegressor(n_estimators=100,criterion=\"mse\",max_depth = None,\n                               max_features='auto', bootstrap=True, n_jobs=-1,verbose = 0,oob_score=True)\nc1.fit(X_ols_train, y_train)\ny1 = c1.predict(X_ols_test)\noob1 = c1.oob_score_\n\nc2 = RandomForestRegressor(n_estimators=100,criterion=\"mse\",max_depth = None,\n                               max_features='sqrt', bootstrap=True, n_jobs=-1,verbose = 0,oob_score=True)\nc2.fit(X_ols_train, y_train)\ny2 = c2.predict(X_ols_test)\noob2 = c2.oob_score_\n\nc3 = RandomForestRegressor(n_estimators=100,criterion=\"mse\",max_depth = None,\n                               max_features='log2', bootstrap=True, n_jobs=-1,verbose = 0,oob_score=True)\nc3.fit(X_ols_train, y_train)\ny3 = c3.predict(X_ols_test)\noob3 = c3.oob_score_\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(oob1, oob2, oob3)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Error scores","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"explained_variance_score(y_test, y_pred_rf)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"max_error(y_test, y_pred_rf)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"mean_absolute_error(y_test, y_pred_rf)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"mean_squared_error(y_test, y_pred_rf)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"median_absolute_error(y_test, y_pred_rf)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import GridSearchCV\nfrom sklearn.model_selection import ShuffleSplit","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"param_grid = { \n            \"n_estimators\"      : [10,20,30,50,100,150,200,250,300,350],\n            \"max_features\"      : [\"auto\", \"sqrt\", \"log2\"],\n            \"min_samples_split\" : [2,4,8,10,15,20],\n            \"bootstrap\": [True, False],\n            \"ccp_alpha\":[0,10,20,30,40,50,100]\n            }\n\ngrid = GridSearchCV(reg_rf, param_grid, n_jobs=-1, cv=5)\n\ngrid.fit(X_ols_train, y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"grid.best_params_","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Bootstrap = True and training and selecting the best params which gridsearchcv predicted.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.ensemble import RandomForestRegressor\nreg_rf = RandomForestRegressor(n_estimators=150,criterion=\"mse\",max_depth = None,\n                               max_features='log2',min_samples_split = 20, bootstrap=True, n_jobs=-1,verbose = 0,oob_score=True)\nreg_rf.fit(X_ols_train, y_train)\ny_pred_rf = reg_rf.predict(X_ols_test)\n\nfrom sklearn.model_selection import cross_val_score\naccuracies = cross_val_score(estimator = reg_rf, X = X_ols_train, y = y_train, cv = 5)\naccuracies.std()\naccuracies.mean()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# X_ols_train.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# X_ols_test = X_ols_test.drop(columns=['const'])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# XGBOOST REGRESSOR","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"import xgboost\nfrom xgboost import XGBRegressor","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"xgb = XGBRegressor(booster = \"gbtree\",tree_method=\"hist\")\nxgb.fit(X_ols_train,y_train)\n\nxgb.get_params()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"xgb.feature_importances_","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Hyperparameter Tuning","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"parameters = {'objective':['reg:linear'],\n              'learning_rate': [0.01,.03, 0.05, 0.07], #so called `eta` value\n              'max_depth': [5,10,15,20],\n#               'min_child_weight': [3,4],              \n#               'subsample': [0.7],\n              \n              'n_estimators': [100,150,200,250,300],\n               'gamma':[0]}\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import GridSearchCV\nxgb1 = XGBRegressor(booster = \"gbtree\",tree_method=\"hist\")\n\n\nxgb_grid = GridSearchCV(xgb1,parameters,cv = 5,n_jobs = 5,verbose=True)\nxgb_grid.fit(X_ols_train,y_train)\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"xgb_grid.best_params_","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"xgb_grid2 = XGBRegressor(\n learning_rate= 0.2,\n max_depth= 2,\n min_child_weight= 4,\n n_estimators= 100,\ntree_method=\"hist\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"xgb_grid2.fit(X_ols_train,y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_xgb = xgb_grid2.predict(X_ols_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\nfrom sklearn.model_selection import cross_val_score\naccuracies = cross_val_score(estimator = xgb_grid2, X = X_ols_train, y = y_train, cv = 5)\naccuracies.std()\naccuracies.mean()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"mean_squared_error(y_test, y_xgb)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"explained_variance_score(y_test,y_xgb)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"max_error(y_test,y_xgb)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Residual plot","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"visualizer = ResidualsPlot(xgb_grid2)\nvisualizer.fit(X_ols_train, y_train)  # Fit the training data to the visualizer\nvisualizer.score(X_ols_test, y_test)  # Evaluate the model on the test data\nvisualizer.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Learning plot","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"from yellowbrick.model_selection import LearningCurve\nvisualizer = LearningCurve(xgb_grid2, scoring='r2')\nvisualizer.fit(X_ols_train, y_train)        # Fit the data to the visualizer\nvisualizer.show()  ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from xgboost import plot_tree\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plot_tree(xgb_grid2,num_trees=99)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# xgb_grid2.plot_importances_(X_ols_train.columns) \n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}